

<!DOCTYPE html>
<html lang="en-US">

<head>
<meta charset="utf-8" />
<title></title>

<link rel="stylesheet" href="https://class.coursera.org/assets/core/css/bootstrap.min.css" />
<link rel="stylesheet" href="https://class.coursera.org/assets/core/css/main.css" />
<link rel="stylesheet" href="https://spark-public.s3.amazonaws.com/nlp/static/css/main.css" />
<link rel="stylesheet" href="https://class.coursera.org/assets/core/css/font-awesome.css" />
<script type="text/javascript" src="https://class.coursera.org/assets/core/js/jquery.js"></script>
<script type="text/javascript" src="https://class.coursera.org/assets/core/js/json.js"></script>
<script type="text/javascript" src="https://class.coursera.org/assets/core/js/hc_fix.js"></script>
<script type="text/javascript" src="https://class.coursera.org/assets/app/admin/i18n/js/i18n_editor.js"></script>
<script src="https://class.coursera.org/assets/core/js/bootstrap/bootstrap-modal.js" type="text/javascript"></script>
<script src="https://class.coursera.org/assets/core/js/modal_focus.js" type="text/javascript"></script>
<script src="https://class.coursera.org/assets/core/js/bind_modal_focus.js" type="text/javascript"></script>
<link rel="stylesheet" href="https://class.coursera.org/assets/app/admin/tooltips/css/tooltips.css">
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-28377374-1']);
  _gaq.push(['_setDomainName', 'coursera.org']);
  _gaq.push(['_setAllowLinker', true]);  
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script><link rel="icon" href="https://spark-public.s3.amazonaws.com/nlp/static/images/favicon.ico" />

</head>

<body>

    <a href="#page-content" class="hidden">Skip Navigation</a>

	
<div class="topbar">
    <div class="topbar-inner">
        <div class="container-fluid"
                          style="background-color: #822"
                          >
            <a target="_new" href="http://www.coursera.org/" class="brand">
				Coursera				<span style="background-color:#387690;padding-top:100px" class="label warning">Beta</span>
			</a>
            <ul class="nav secondary-nav">
                                                    <li style="padding: 10px 10px 11px; color:#BFBFBF; font-size:14px; border-right: solid 1px #333">Jason Bau</li>
                    <li><a href="https://class.coursera.org/nlp-staging/class/preferences">Preferences</a></li>
                    <li><a href="http://www.coursera.org/">All Courses</a></li>

                                            <li><a href="https://class.coursera.org/nlp-staging/admin/index">Admin</a></li>
                        <li><a href="https://class.coursera.org/nlp-staging/admin/support_external">Support</a></li>
                                        
                                            <li><a id="i18n_editor" href="#">I18N Editor</a></li>
                    
                    <li><a href="https://class.coursera.org/nlp-staging/class/aboutus">About</a></li>
                    <li><a href="https://class.coursera.org/nlp-staging/auth/feedback">Contact Us</a></li>
                    <li><a href="https://class.coursera.org/nlp-staging/auth/logout">Logout</a></li>
                            </ul>
        </div>
    </div>
</div>


    <div id="banner-top">
    	<div id="course-logo-text">
        	<a href="https://class.coursera.org/nlp-staging/class/index">
        		<img border="0" alt="Natural Language Processing" src="https://spark-public.s3.amazonaws.com/nlp/static/images/course-logo-text.png" />
        	</a>
        </div>
    	<div id="banner-course-info">
        	<div class="course-instructor-name">Dan Jurafsky, <span style="font-weight:normal">Professor of Linguistics</span><br />
Chris Manning, <span style="font-weight:normal">Associate Professor of Computer Science</span></div>
            <div class="course-time"></div>
        </div>
    </div>
    
        <div class="container-fluid">
        <div class="sidebar page-sidebar" id="page-sidebar">
            <h3><a href="https://class.coursera.org/nlp-staging/admin/index">Administration</a></h3>

<b>General</b>
<ul>
	<li><a href="https://class.coursera.org/nlp-staging/admin/courseadmin/index">Course Settings</a></li>
		<li><a href="https://class.coursera.org/nlp-staging/admin/staging/index">Deployment &amp; Staging </a></li>
		<li><a href="https://class.coursera.org/nlp-staging/admin/grading_policy/index">Grading Policy</a></li> 
		<li><a href="https://class.coursera.org/nlp-staging/admin/navbar/index">Navigation Bar Settings</a></li>
	            <li><a href="https://class.coursera.org/nlp-staging/admin/announcement/index">Announcement Management</a></li>
        </ul>

<b>Content Management</b>
<ul>
	<li><a href="https://class.coursera.org/nlp-staging/admin/quiz/index">Quiz Management</a></li>
  <li><a href="https://class.coursera.org/nlp-staging/admin/assignment/index">Assignment Management</a></li>
<!--
  <li><a href="https://class.coursera.org/nlp-staging/admin/creative_assignments/index">Creative Assignments</a></li>
-->
	<li><a href="https://class.coursera.org/nlp-staging/admin/lecture/index">Lecture Management</a></li>
	<li><a href="https://class.coursera.org/nlp-staging/admin/section/index">Section Management</a></li>
	<li><a href="https://class.coursera.org/nlp-staging/admin/courseadmin/announcement">Upcoming Items Display</a></li>
</ul>
<b>Platform Services</b>
<ul>
        <li><a href="https://class.coursera.org/nlp-staging/admin/assets/index">Asset Administration</a></li>
  	<li><a href="https://class.coursera.org/nlp-staging/admin/forum/index">Forum Administration</a></li>
    	<li><a href="https://class.coursera.org/nlp-staging/admin/email/index">Email Users</a></li>	
</ul>

<b>Advanced Tools</b>
<ul>
	<li><a href="https://class.coursera.org/nlp-staging/admin/queue/index">Queue Administration</a></li>
   
    	<li><a href="https://class.coursera.org/nlp-staging/admin/staging/time_shift">Chronos</a></li>
    	    <li><a href="https://class.coursera.org/nlp-staging/admin/log/index">Log Viewer</a></li>
    		<li><a href="https://class.coursera.org/nlp-staging/admin/user/index">User Administration</a></li>
	</ul>

<b>Import Tools</b>
<ul>
	<li><a href="https://class.coursera.org/nlp-staging/admin/assignment/import">Assignment Submissions</a></li>
</ul>
<b>Export Tools</b>
<ul>
	<li><a href="https://class.coursera.org/nlp-staging/admin/export/quiz_responses">Quiz Summary</a></li>
	<li><a href="https://class.coursera.org/nlp-staging/admin/export/detailed_quiz_responses">Detailed Quiz Responses</a></li>
	<li><a href="https://class.coursera.org/nlp-staging/admin/export/assignment_submissions">Assignment Submissions</a></li>
	<li><a href="https://class.coursera.org/nlp-staging/admin/export/gradebook">Class Gradebook</a></li>
</ul>

<b>Status Monitoring</b>
<ul>
    <li><a href="https://class.coursera.org/nlp-staging/admin/stats/activity">Activity Tracking</a></li>
    <li><a href="https://class.coursera.org/nlp-staging/admin/stats/export">Export Statistics</a></li> 
        <li><a href="https://class.coursera.org/nlp-staging/admin/lecture/recode_status">Video Status</a></li>
</ul>
        </div>
        <div class="content page-content" id="page-content">
            <script src="https://class.coursera.org/assets/app/admin/quiz/codemirror/lib/codemirror.js" type="text/javascript"></script>
<script src="https://class.coursera.org/assets/app/admin/quiz/codemirror/mode/xml/xml.js" type="text/javascript"></script>
<link rel="stylesheet" type="text/css" href="https://class.coursera.org/assets/app/admin/quiz/codemirror/lib/codemirror.css"/>

<form method="post" action="https://class.coursera.org/nlp-staging/admin/quiz/raw_save">
<textarea rows="24" cols="96" style="width: 640px" id="quiz_xml" name="quiz_xml">
&lt;quiz&gt;
  &lt;metadata&gt;
    &lt;title&gt;Text Classification and Sentiment Analysis&lt;/title&gt;
    &lt;open_time&gt;2012-03-24 0001&lt;/open_time&gt;
    &lt;soft_close_time&gt;2012-04-10 2359&lt;/soft_close_time&gt;
    &lt;hard_close_time&gt;2012-05-22 2359&lt;/hard_close_time&gt;
    &lt;duration&gt;0&lt;/duration&gt;
    &lt;retry_delay&gt;10&lt;/retry_delay&gt;
    &lt;maximum_submissions&gt;5&lt;/maximum_submissions&gt;
    &lt;modified_time&gt;1335394001389&lt;/modified_time&gt;
    &lt;parameters&gt;
      &lt;show_explanations&gt;
        &lt;question&gt;after_hard_close_time&lt;/question&gt;
        &lt;option&gt;before_soft_close_time&lt;/option&gt;
        &lt;score&gt;before_soft_close_time&lt;/score&gt;
      &lt;/show_explanations&gt;
    &lt;/parameters&gt;
    &lt;maximum_score&gt;4&lt;/maximum_score&gt;
  &lt;/metadata&gt;
  &lt;preamble&gt;&lt;![CDATA[]]&gt;&lt;/preamble&gt;
  &lt;data&gt;
    &lt;question_groups&gt;
      &lt;question_group select=&quot;1&quot;&gt;
        &lt;preamble&gt;&lt;![CDATA[]]&gt;&lt;/preamble&gt;
        &lt;question id=&quot;ee7461fca29652c5160f875e7dfdcfe2&quot; type=&quot;GS_Choice_Answer_Question&quot;&gt;
          &lt;metadata&gt;
            &lt;parameters&gt;
              &lt;rescale_score&gt;1&lt;/rescale_score&gt;
              &lt;choice_type&gt;radio&lt;/choice_type&gt;
            &lt;/parameters&gt;
          &lt;/metadata&gt;
          &lt;data&gt;
            &lt;text&gt;&lt;![CDATA[&lt;p&gt;Assume the following probabilities for each word being part of a &lt;em&gt;positive&lt;/em&gt; or &lt;em&gt;negative&lt;/em&gt; movie review.&lt;/p&gt;
&lt;table&gt;
&lt;tr&gt;&lt;td&gt; &lt;/td&gt;&lt;td&gt;&lt;b&gt;pos&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;neg&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;em&gt;I&lt;/em&gt;&lt;/td&gt;&lt;td&gt;0.09&lt;/td&gt;&lt;td&gt;0.16&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;em&gt;always&lt;/em&gt;&lt;/td&gt;&lt;td&gt;0.07&lt;/td&gt;&lt;td&gt;0.06&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;em&gt;like&lt;/em&gt;&lt;/td&gt;&lt;td&gt;0.29&lt;/td&gt;&lt;td&gt;0.06&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;em&gt;foreign&lt;/em&gt;&lt;/td&gt;&lt;td&gt;0.04&lt;/td&gt;&lt;td&gt;0.15&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;em&gt;films&lt;/em&gt;&lt;/td&gt;&lt;td&gt;0.08&lt;/td&gt;&lt;td&gt;0.11&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Now consider the sentence...
&lt;pre&gt;I always like foreign films.&lt;/pre&gt;
&lt;p&gt;Using Naïve Bayes and assuming equal prior probability for each class, will we classify this sentence as being part of a &lt;em&gt;positive&lt;/em&gt; or &lt;em&gt;negative&lt;/em&gt; review?]]&gt;&lt;/text&gt;
            &lt;explanation&gt;&lt;![CDATA[With Naïve Bayes as a language model, we're looking for the class that maximizes the probability of the sentence. (See lecture slide #41 in the slide set on Text Classification and Naïve Bayes.) Because we're looking for the argmax, we can ignore the denominator (the likelihood of the sentence, in general), and the question states that the classes have equal prior probability, so we simply find the product of the likelihoods of each word, i.e., multiply each column and take the larger.]]&gt;&lt;/explanation&gt;
            &lt;option_groups randomize=&quot;true&quot;&gt;
              &lt;option_group select=&quot;all&quot;&gt;
                &lt;option id=&quot;ba126b60767fc0afa50c65746dbfb1c9&quot; selected_score=&quot;0&quot; unselected_score=&quot;0&quot;&gt;
                  &lt;text&gt;&lt;![CDATA[pos]]&gt;&lt;/text&gt;
                  &lt;explanation&gt;&lt;![CDATA[]]&gt;&lt;/explanation&gt;
                &lt;/option&gt;
                &lt;option id=&quot;d29d3fae07eeb19822dfb5e63bac1064&quot; selected_score=&quot;1&quot; unselected_score=&quot;0&quot;&gt;
                  &lt;text&gt;&lt;![CDATA[neg]]&gt;&lt;/text&gt;
                  &lt;explanation&gt;&lt;![CDATA[]]&gt;&lt;/explanation&gt;
                &lt;/option&gt;
              &lt;/option_group&gt;
            &lt;/option_groups&gt;
          &lt;/data&gt;
        &lt;/question&gt;
        &lt;question id=&quot;09485f335f62d944f2c09036ba973d67&quot; type=&quot;GS_Choice_Answer_Question&quot;&gt;
          &lt;metadata&gt;
            &lt;parameters&gt;
              &lt;rescale_score&gt;1&lt;/rescale_score&gt;
              &lt;choice_type&gt;radio&lt;/choice_type&gt;
            &lt;/parameters&gt;
          &lt;/metadata&gt;
          &lt;data&gt;
            &lt;text&gt;&lt;![CDATA[&lt;p&gt;Assume the following probabilities for each word being part of a &lt;em&gt;positive&lt;/em&gt; or &lt;em&gt;negative&lt;/em&gt; movie review.&lt;/p&gt;
&lt;table&gt;
&lt;tr&gt;&lt;td&gt; &lt;/td&gt;&lt;td&gt;&lt;b&gt;pos&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;neg&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;em&gt;I&lt;/em&gt;&lt;/td&gt;&lt;td&gt;0.09&lt;/td&gt;&lt;td&gt;0.18&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;em&gt;always&lt;/em&gt;&lt;/td&gt;&lt;td&gt;0.09&lt;/td&gt;&lt;td&gt;0.05&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;em&gt;like&lt;/em&gt;&lt;/td&gt;&lt;td&gt;0.19&lt;/td&gt;&lt;td&gt;0.04&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;em&gt;foreign&lt;/em&gt;&lt;/td&gt;&lt;td&gt;0.04&lt;/td&gt;&lt;td&gt;0.11&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;em&gt;films&lt;/em&gt;&lt;/td&gt;&lt;td&gt;0.09&lt;/td&gt;&lt;td&gt;0.12&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Now consider the sentence...
&lt;pre&gt;I always like foreign films.&lt;/pre&gt;
&lt;p&gt;Using Naïve Bayes and assuming equal prior probability for each class, will we classify this sentence as being part of a &lt;em&gt;positive&lt;/em&gt; or &lt;em&gt;negative&lt;/em&gt; review?]]&gt;&lt;/text&gt;
            &lt;explanation&gt;&lt;![CDATA[With Naïve Bayes as a language model, we're looking for the class that maximizes the probability of the sentence. (See lecture slide #41 in the slide set on Text Classification and Naïve Bayes.) Because we're looking for the argmax, we can ignore the denominator (the likelihood of the sentence, in general), and the question states that the classes have equal prior probability, so we simply find the product of the likelihoods of each word, i.e., multiply each column and take the larger.]]&gt;&lt;/explanation&gt;
            &lt;option_groups randomize=&quot;true&quot;&gt;
              &lt;option_group select=&quot;all&quot;&gt;
                &lt;option id=&quot;000fa845ea842053b13038aab2d0b528&quot; selected_score=&quot;1&quot; unselected_score=&quot;0&quot;&gt;
                  &lt;text&gt;&lt;![CDATA[pos]]&gt;&lt;/text&gt;
                  &lt;explanation&gt;&lt;![CDATA[]]&gt;&lt;/explanation&gt;
                &lt;/option&gt;
                &lt;option id=&quot;a8e4ad605a27d5b78d0fb3466304fe46&quot; selected_score=&quot;0&quot; unselected_score=&quot;0&quot;&gt;
                  &lt;text&gt;&lt;![CDATA[neg]]&gt;&lt;/text&gt;
                  &lt;explanation&gt;&lt;![CDATA[]]&gt;&lt;/explanation&gt;
                &lt;/option&gt;
              &lt;/option_group&gt;
            &lt;/option_groups&gt;
          &lt;/data&gt;
        &lt;/question&gt;
        &lt;question id=&quot;333702857bda0e8864193110b5dac67c&quot; type=&quot;GS_Choice_Answer_Question&quot;&gt;
          &lt;metadata&gt;
            &lt;parameters&gt;
              &lt;rescale_score&gt;1&lt;/rescale_score&gt;
              &lt;choice_type&gt;radio&lt;/choice_type&gt;
            &lt;/parameters&gt;
          &lt;/metadata&gt;
          &lt;data&gt;
            &lt;text&gt;&lt;![CDATA[&lt;p&gt;Assume the following probabilities for each word being part of a &lt;em&gt;positive&lt;/em&gt; or &lt;em&gt;negative&lt;/em&gt; movie review.&lt;/p&gt;
&lt;table&gt;
&lt;tr&gt;&lt;td&gt; &lt;/td&gt;&lt;td&gt;&lt;b&gt;pos&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;neg&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;em&gt;I&lt;/em&gt;&lt;/td&gt;&lt;td&gt;0.13&lt;/td&gt;&lt;td&gt;0.29&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;em&gt;always&lt;/em&gt;&lt;/td&gt;&lt;td&gt;0.08&lt;/td&gt;&lt;td&gt;0.06&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;em&gt;like&lt;/em&gt;&lt;/td&gt;&lt;td&gt;0.19&lt;/td&gt;&lt;td&gt;0.03&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;em&gt;foreign&lt;/em&gt;&lt;/td&gt;&lt;td&gt;0.07&lt;/td&gt;&lt;td&gt;0.21&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;em&gt;films&lt;/em&gt;&lt;/td&gt;&lt;td&gt;0.11&lt;/td&gt;&lt;td&gt;0.14&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Now consider the sentence...
&lt;pre&gt;I always like foreign films.&lt;/pre&gt;
&lt;p&gt;Using Naïve Bayes and assuming equal prior probability for each class, will we classify this sentence as being part of a &lt;em&gt;positive&lt;/em&gt; or &lt;em&gt;negative&lt;/em&gt; review?]]&gt;&lt;/text&gt;
            &lt;explanation&gt;&lt;![CDATA[With Naïve Bayes as a language model, we're looking for the class that maximizes the probability of the sentence. (See lecture slide #41 in the slide set on Text Classification and Naïve Bayes.) Because we're looking for the argmax, we can ignore the denominator (the likelihood of the sentence, in general), and the question states that the classes have equal prior probability, so we simply find the product of the likelihoods of each word, i.e., multiply each column and take the larger.]]&gt;&lt;/explanation&gt;
            &lt;option_groups randomize=&quot;true&quot;&gt;
              &lt;option_group select=&quot;all&quot;&gt;
                &lt;option id=&quot;b2e0581966a40904dce7e174cc982de9&quot; selected_score=&quot;0&quot; unselected_score=&quot;0&quot;&gt;
                  &lt;text&gt;&lt;![CDATA[pos]]&gt;&lt;/text&gt;
                  &lt;explanation&gt;&lt;![CDATA[]]&gt;&lt;/explanation&gt;
                &lt;/option&gt;
                &lt;option id=&quot;82bb1ea4a42f1d0c1cec28d588416723&quot; selected_score=&quot;1&quot; unselected_score=&quot;0&quot;&gt;
                  &lt;text&gt;&lt;![CDATA[neg]]&gt;&lt;/text&gt;
                  &lt;explanation&gt;&lt;![CDATA[]]&gt;&lt;/explanation&gt;
                &lt;/option&gt;
              &lt;/option_group&gt;
            &lt;/option_groups&gt;
          &lt;/data&gt;
        &lt;/question&gt;
      &lt;/question_group&gt;
      &lt;question_group select=&quot;1&quot;&gt;
        &lt;preamble&gt;&lt;![CDATA[]]&gt;&lt;/preamble&gt;
        &lt;question id=&quot;1461ffb2467828b486e50f181d416635&quot; type=&quot;GS_Choice_Answer_Question&quot;&gt;
          &lt;metadata&gt;
            &lt;parameters&gt;
              &lt;rescale_score&gt;1&lt;/rescale_score&gt;
              &lt;choice_type&gt;radio&lt;/choice_type&gt;
            &lt;/parameters&gt;
          &lt;/metadata&gt;
          &lt;data&gt;
            &lt;text&gt;&lt;![CDATA[&lt;p&gt;Suppose we have the following short movie reviews, each labeled with a genre, either &lt;em&gt;comedy&lt;/em&gt; or &lt;em&gt;action&lt;/em&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;tr&gt;&lt;td&gt;1.&lt;/td&gt;&lt;td&gt;fun, couple, love, love&lt;/td&gt;&lt;td&gt;&lt;b&gt;comedy&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2.&lt;/td&gt;&lt;td&gt;fast, furious, shoot&lt;/td&gt;&lt;td&gt;&lt;b&gt;action&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3.&lt;/td&gt;&lt;td&gt;couple, fly, fast, fun, fun&lt;/td&gt;&lt;td&gt;&lt;b&gt;comedy&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4.&lt;/td&gt;&lt;td&gt;furious, shoot, shoot, fun&lt;/td&gt;&lt;td&gt;&lt;b&gt;action&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5.&lt;/td&gt;&lt;td&gt;fly, fast, shoot, love&lt;/td&gt;&lt;td&gt;&lt;b&gt;action&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;Now consider the following new review...&lt;/p&gt;
&lt;pre&gt;
fast, couple, shoot, fly
&lt;/pre&gt;
Using a simple $$Naïve$$ $$Bayes$$ approach with $$Laplace$$ $$Smoothing$$, how would we classify this, &lt;em&gt;comedy&lt;/em&gt; or &lt;em&gt;action&lt;/em&gt;? &lt;b&gt;&lt;em&gt;(Hint: Don't forget to include the prior.)]]&gt;&lt;/text&gt;
            &lt;explanation&gt;&lt;![CDATA[(See lecture slide #44 in the slide set on Text Classification and Naïve Bayes.) If &lt;em&gt;r&lt;/em&gt; is our new review, we're looking for the class (genre) that maximizes (argmax) &lt;em&gt;P(c|r)&lt;/em&gt;, where &lt;em&gt;P(c|r)&lt;/em&gt; is proportional to the prior probability of the class, &lt;em&gt;P(c)&lt;/em&gt;, times the product of &lt;em&gt;P(w|c)&lt;/em&gt; for each word in &lt;em&gt;r&lt;/em&gt;. &lt;em&gt;P(c)&lt;/em&gt; is the number of reviews for each genre, divided by the total number of reviews. &lt;em&gt;P(w|c)&lt;/em&gt; is the count of word &lt;em&gt;w&lt;/em&gt; in class &lt;em&gt;c&lt;/em&gt; plus 1 (i.e., smoothed), divided by the total count for &lt;em&gt;w&lt;/em&gt; plus the vocabulary size (the number of unique words).]]&gt;&lt;/explanation&gt;
            &lt;option_groups randomize=&quot;true&quot;&gt;
              &lt;option_group select=&quot;all&quot;&gt;
                &lt;option id=&quot;d1176eb077773d390c27d02ede9c128a&quot; selected_score=&quot;0&quot; unselected_score=&quot;0&quot;&gt;
                  &lt;text&gt;&lt;![CDATA[comedy]]&gt;&lt;/text&gt;
                  &lt;explanation&gt;&lt;![CDATA[]]&gt;&lt;/explanation&gt;
                &lt;/option&gt;
                &lt;option id=&quot;1fd12aa962c43c1d1792d15423761880&quot; selected_score=&quot;1&quot; unselected_score=&quot;0&quot;&gt;
                  &lt;text&gt;&lt;![CDATA[action]]&gt;&lt;/text&gt;
                  &lt;explanation&gt;&lt;![CDATA[]]&gt;&lt;/explanation&gt;
                &lt;/option&gt;
              &lt;/option_group&gt;
            &lt;/option_groups&gt;
          &lt;/data&gt;
        &lt;/question&gt;
        &lt;question id=&quot;22c018825c89bf4e4de03c195bdfc693&quot; type=&quot;GS_Choice_Answer_Question&quot;&gt;
          &lt;metadata&gt;
            &lt;parameters&gt;
              &lt;rescale_score&gt;1&lt;/rescale_score&gt;
              &lt;choice_type&gt;radio&lt;/choice_type&gt;
            &lt;/parameters&gt;
          &lt;/metadata&gt;
          &lt;data&gt;
            &lt;text&gt;&lt;![CDATA[&lt;p&gt;Suppose we have the following short movie reviews, each labeled with a genre, either &lt;em&gt;comedy&lt;/em&gt; or &lt;em&gt;action&lt;/em&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;tr&gt;&lt;td&gt;1.&lt;/td&gt;&lt;td&gt;fun, couple, love, love&lt;/td&gt;&lt;td&gt;&lt;b&gt;comedy&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2.&lt;/td&gt;&lt;td&gt;fast, furious, shoot&lt;/td&gt;&lt;td&gt;&lt;b&gt;action&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3.&lt;/td&gt;&lt;td&gt;couple, fly, fast, fun, fun&lt;/td&gt;&lt;td&gt;&lt;b&gt;comedy&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4.&lt;/td&gt;&lt;td&gt;furious, shoot, shoot, fun&lt;/td&gt;&lt;td&gt;&lt;b&gt;action&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5.&lt;/td&gt;&lt;td&gt;fly, fast, shoot, love&lt;/td&gt;&lt;td&gt;&lt;b&gt;action&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;Now consider the following new review...&lt;/p&gt;
&lt;pre&gt;
fun, couple, shoot, fast
&lt;/pre&gt;
Using a simple $$Naïve$$ $$Bayes$$ approach with $$Laplace$$ $$Smoothing$$, how would we classify this, &lt;em&gt;comedy&lt;/em&gt; or &lt;em&gt;action&lt;/em&gt;? &lt;b&gt;&lt;em&gt;(Hint: Don't forget to include the prior.)]]&gt;&lt;/text&gt;
            &lt;explanation&gt;&lt;![CDATA[(See lecture slide #44 in the slide set on Text Classification and Naïve Bayes.) If &lt;em&gt;r&lt;/em&gt; is our new review, we're looking for the class (genre) that maximizes (argmax) &lt;em&gt;P(c|r)&lt;/em&gt;, where &lt;em&gt;P(c|r)&lt;/em&gt; is proportional to the prior probability of the class, &lt;em&gt;P(c)&lt;/em&gt;, times the product of &lt;em&gt;P(w|c)&lt;/em&gt; for each word in &lt;em&gt;r&lt;/em&gt;. &lt;em&gt;P(c)&lt;/em&gt; is the number of reviews for each genre, divided by the total number of reviews. &lt;em&gt;P(w|c)&lt;/em&gt; is the count of word &lt;em&gt;w&lt;/em&gt; in class &lt;em&gt;c&lt;/em&gt; plus 1 (i.e., smoothed), divided by the total count for &lt;em&gt;w&lt;/em&gt; plus the vocabulary size (the number of unique words).]]&gt;&lt;/explanation&gt;
            &lt;option_groups randomize=&quot;true&quot;&gt;
              &lt;option_group select=&quot;all&quot;&gt;
                &lt;option id=&quot;283966c37410fce58fc269d13b3381a9&quot; selected_score=&quot;0&quot; unselected_score=&quot;0&quot;&gt;
                  &lt;text&gt;&lt;![CDATA[comedy]]&gt;&lt;/text&gt;
                  &lt;explanation&gt;&lt;![CDATA[]]&gt;&lt;/explanation&gt;
                &lt;/option&gt;
                &lt;option id=&quot;f9b1ee4d3dad4e6f5a18147512bdbc42&quot; selected_score=&quot;1&quot; unselected_score=&quot;0&quot;&gt;
                  &lt;text&gt;&lt;![CDATA[action]]&gt;&lt;/text&gt;
                  &lt;explanation&gt;&lt;![CDATA[]]&gt;&lt;/explanation&gt;
                &lt;/option&gt;
              &lt;/option_group&gt;
            &lt;/option_groups&gt;
          &lt;/data&gt;
        &lt;/question&gt;
        &lt;question id=&quot;95941c15e28af765a71ef21697ef10ee&quot; type=&quot;GS_Choice_Answer_Question&quot;&gt;
          &lt;metadata&gt;
            &lt;parameters&gt;
              &lt;rescale_score&gt;1&lt;/rescale_score&gt;
              &lt;choice_type&gt;radio&lt;/choice_type&gt;
            &lt;/parameters&gt;
          &lt;/metadata&gt;
          &lt;data&gt;
            &lt;text&gt;&lt;![CDATA[&lt;p&gt;Suppose we have the following short movie reviews, each labeled with a genre, either &lt;em&gt;comedy&lt;/em&gt; or &lt;em&gt;action&lt;/em&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;tr&gt;&lt;td&gt;1.&lt;/td&gt;&lt;td&gt;fun, couple, love, love&lt;/td&gt;&lt;td&gt;&lt;b&gt;comedy&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2.&lt;/td&gt;&lt;td&gt;fast, furious, shoot&lt;/td&gt;&lt;td&gt;&lt;b&gt;action&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;3.&lt;/td&gt;&lt;td&gt;couple, fly, fast, fun, fun&lt;/td&gt;&lt;td&gt;&lt;b&gt;comedy&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;4.&lt;/td&gt;&lt;td&gt;furious, shoot, shoot, fun&lt;/td&gt;&lt;td&gt;&lt;b&gt;action&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;5.&lt;/td&gt;&lt;td&gt;fly, fast, shoot, love&lt;/td&gt;&lt;td&gt;&lt;b&gt;action&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;Now consider the following new review...&lt;/p&gt;
&lt;pre&gt;
fast, furious, fun
&lt;/pre&gt;
Using a simple $$Naïve$$ $$Bayes$$ approach with $$Laplace$$ $$Smoothing$$, how would we classify this, &lt;em&gt;comedy&lt;/em&gt; or &lt;em&gt;action&lt;/em&gt;? &lt;b&gt;&lt;em&gt;(Hint: Don't forget to include the prior.)]]&gt;&lt;/text&gt;
            &lt;explanation&gt;&lt;![CDATA[(See lecture slide #44 in the slide set on Text Classification and Naïve Bayes.) If &lt;em&gt;r&lt;/em&gt; is our new review, we're looking for the class (genre) that maximizes (argmax) &lt;em&gt;P(c|r)&lt;/em&gt;, where &lt;em&gt;P(c|r)&lt;/em&gt; is proportional to the prior probability of the class, &lt;em&gt;P(c)&lt;/em&gt;, times the product of &lt;em&gt;P(w|c)&lt;/em&gt; for each word in &lt;em&gt;r&lt;/em&gt;. &lt;em&gt;P(c)&lt;/em&gt; is the number of reviews for each genre, divided by the total number of reviews. &lt;em&gt;P(w|c)&lt;/em&gt; is the count of word &lt;em&gt;w&lt;/em&gt; in class &lt;em&gt;c&lt;/em&gt; plus 1 (i.e., smoothed), divided by the total count for &lt;em&gt;w&lt;/em&gt; plus the vocabulary size (the number of unique words).]]&gt;&lt;/explanation&gt;
            &lt;option_groups randomize=&quot;true&quot;&gt;
              &lt;option_group select=&quot;all&quot;&gt;
                &lt;option id=&quot;d881e47f9bfa824a2bf10804e8697b96&quot; selected_score=&quot;0&quot; unselected_score=&quot;0&quot;&gt;
                  &lt;text&gt;&lt;![CDATA[comedy]]&gt;&lt;/text&gt;
                  &lt;explanation&gt;&lt;![CDATA[]]&gt;&lt;/explanation&gt;
                &lt;/option&gt;
                &lt;option id=&quot;e7f93d5942db3582289e2d18d3980e43&quot; selected_score=&quot;1&quot; unselected_score=&quot;0&quot;&gt;
                  &lt;text&gt;&lt;![CDATA[action]]&gt;&lt;/text&gt;
                  &lt;explanation&gt;&lt;![CDATA[]]&gt;&lt;/explanation&gt;
                &lt;/option&gt;
              &lt;/option_group&gt;
            &lt;/option_groups&gt;
          &lt;/data&gt;
        &lt;/question&gt;
      &lt;/question_group&gt;
      &lt;question_group select=&quot;1&quot;&gt;
        &lt;preamble&gt;&lt;![CDATA[]]&gt;&lt;/preamble&gt;
        &lt;question id=&quot;aeef142288f28222b2e5f5b2054b0ab0&quot; type=&quot;GS_Short_Answer_Question_Simple&quot;&gt;
          &lt;metadata&gt;
            &lt;parameters&gt;
              &lt;rescale_score&gt;1&lt;/rescale_score&gt;
              &lt;type&gt;numeric&lt;/type&gt;
            &lt;/parameters&gt;
          &lt;/metadata&gt;
          &lt;data&gt;
            &lt;text&gt;&lt;![CDATA[&lt;p&gt;As part of learning a sentiment lexicon for analyzing movie reviews, you decide to use the $$Turney$$ $$Polarity$$ method to compute the (real-valued) polarity of the phrase $$''special$$ $$effects''$$ using $$Pointwise$$ $$Mutual$$ $$Information$$ relative to the sentiment words $$''good''$$ and $$''bad''$$.

&lt;p&gt;Here are some actual counts from a corpus of IMDB reviews, where &lt;b&gt;NEAR&lt;/b&gt; means &quot;within 10 words of&quot;.&lt;/p&gt;
&lt;table&gt;
&lt;tr&gt;&lt;td&gt; &lt;/td&gt;&lt;td&gt;&lt;b&gt;&lt;u&gt;count&lt;/u&gt;&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;corpus size (&lt;em&gt;N&lt;/em&gt;)&lt;/td&gt;&lt;td&gt;1,595,494&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;unique types (&lt;em&gt;V&lt;/em&gt;)&lt;/td&gt;&lt;td&gt;46,060&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&quot;special effects&quot;&lt;/td&gt;&lt;td&gt;437&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&quot;good&quot;&lt;/td&gt;&lt;td&gt;3124&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&quot;bad&quot;&lt;/td&gt;&lt;td&gt;1791&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&quot;special effects&quot; &lt;b&gt;NEAR&lt;/b&gt; &quot;good&quot;&lt;/td&gt;&lt;td&gt;36&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&quot;special effects&quot; &lt;b&gt;NEAR&lt;/b&gt; &quot;bad&quot;&lt;/td&gt;&lt;td&gt;18&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Your task is to calculate the value of $$Turney's$$ $$Polarity(''special$$ $$effects'')$$ with regard to $$''good''$$ and $$''bad''$$.&lt;br&gt;
&lt;b&gt;(signed numerical response rounded to the nearest tenth, e.g., 0.1, –0.7, etc.)&lt;/b&gt;&lt;/p&gt;]]&gt;&lt;/text&gt;
            &lt;explanation&gt;&lt;![CDATA[See lecture slide #60 in the section &quot;Learning Sentiment Lexicons&quot;. For this calculation, total size of corpus, vocabulary size, and standalone count of &quot;special effects&quot; are not needed. &lt;em&gt;Polarity(&quot;special effects&quot;) = log&lt;sub&gt;2&lt;/sub&gt;[ (count(&quot;special effects&quot; NEAR &quot;good&quot;) * count(&quot;bad&quot;)) / (count(&quot;special effects&quot; NEAR &quot;bad&quot;) * count(&quot;good&quot;)) ]&lt;/em&gt;.]]&gt;&lt;/explanation&gt;
            &lt;option_groups randomize=&quot;true&quot;&gt;
              &lt;option_group select=&quot;all&quot;&gt;
                &lt;option id=&quot;46510fd78badaf7247ec0ff025450e1d&quot; selected_score=&quot;1&quot; unselected_score=&quot;0&quot;&gt;
                  &lt;text&gt;&lt;![CDATA[0.2]]&gt;&lt;/text&gt;
                  &lt;explanation&gt;&lt;![CDATA[Option explanation]]&gt;&lt;/explanation&gt;
                &lt;/option&gt;
              &lt;/option_group&gt;
            &lt;/option_groups&gt;
          &lt;/data&gt;
        &lt;/question&gt;
      &lt;/question_group&gt;
      &lt;question_group select=&quot;1&quot;&gt;
        &lt;preamble&gt;&lt;![CDATA[]]&gt;&lt;/preamble&gt;
        &lt;question id=&quot;ef4180af3a58737fbc70bf6974bbe491&quot; type=&quot;GS_Choice_Answer_Question&quot;&gt;
          &lt;metadata&gt;
            &lt;parameters&gt;
              &lt;rescale_score&gt;1&lt;/rescale_score&gt;
              &lt;choice_type&gt;radio&lt;/choice_type&gt;
            &lt;/parameters&gt;
          &lt;/metadata&gt;
          &lt;data&gt;
            &lt;text&gt;&lt;![CDATA[&lt;p&gt;Once again we'll look at sentiment in movie reviews, but this time we'll see if our analysis yields a different result with standard $$Naïve$$ $$Bayes$$  vs. a $$Binarized$$ $$(Boolean$$ $$feature)$$ $$Naïve$$ $$Bayes$$ approach.&lt;/p&gt;

&lt;p&gt;We train our classifier with documents having the following &lt;b&gt;&lt;em&gt;counts&lt;/em&gt;&lt;/b&gt; for key sentiment words, with &lt;em&gt;positive&lt;/em&gt; or &lt;em&gt;negative&lt;/em&gt; class assigned as noted.&lt;/p&gt;

&lt;table&gt;
&lt;tr&gt;&lt;td&gt; &lt;/td&gt;&lt;td&gt;&lt;em&gt;&quot;good&quot;&lt;/em&gt;&lt;/td&gt;&lt;td&gt;&lt;em&gt;&quot;poor&quot;&lt;/em&gt;&lt;/td&gt;&lt;td&gt;&lt;em&gt;&quot;great&quot;&lt;/em&gt;&lt;/td&gt;&lt;td&gt;(class)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;d1.&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;&lt;em&gt;pos&lt;/em&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;d2.&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;&lt;em&gt;pos&lt;/em&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;d3.&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;&lt;em&gt;neg&lt;/em&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;d4.&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;&lt;em&gt;neg&lt;/em&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;d5.&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;&lt;em&gt;neg&lt;/em&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Now consider the following new review.&lt;/p&gt;
&lt;pre&gt;Good acting, poor plot.&lt;/pre&gt;

&lt;p&gt;Your task is to assign &lt;em&gt;positive&lt;/em&gt; or &lt;em&gt;negative&lt;/em&gt; sentiment first using standard $$Naïve$$ $$Bayes$$  then with a  $$Binarized$$ $$Naïve$$ $$Bayes$$ approach. Do the different approaches yield the same result in this case? Which of the following matches the pattern of your results? &lt;em&gt;(Hint: Use Add-1 smoothing with &lt;b&gt;both&lt;/b&gt; methods.)&lt;/p&gt;

&lt;p&gt;&lt;b&gt;(response: [&lt;em&gt;standard&lt;/em&gt;] / [&lt;em&gt;binarized&lt;/em&gt;] )&lt;/b&gt;&lt;/p&gt;]]&gt;&lt;/text&gt;
            &lt;explanation&gt;&lt;![CDATA[(See lecture slide on &quot;Binarized (Boolean feature)  Multinomial Naïve Bayes&quot;.) Use the same method in each case, except that for the $$Binarized$$ approach, only count each word a maximum of once per document, i.e., transform the table of counts above to 0 or 1 for each cell.]]&gt;&lt;/explanation&gt;
            &lt;option_groups randomize=&quot;true&quot;&gt;
              &lt;option_group select=&quot;all&quot;&gt;
                &lt;option id=&quot;cff8bab45a28882b12717fd298eaa05a&quot; selected_score=&quot;0&quot; unselected_score=&quot;0&quot;&gt;
                  &lt;text&gt;&lt;![CDATA[pos / pos]]&gt;&lt;/text&gt;
                  &lt;explanation&gt;&lt;![CDATA[Option explanation]]&gt;&lt;/explanation&gt;
                &lt;/option&gt;
                &lt;option id=&quot;767ab9f5466a14c40743614f40d14de6&quot; selected_score=&quot;0&quot; unselected_score=&quot;0&quot;&gt;
                  &lt;text&gt;&lt;![CDATA[pos / neg]]&gt;&lt;/text&gt;
                  &lt;explanation&gt;&lt;![CDATA[Option explanation]]&gt;&lt;/explanation&gt;
                &lt;/option&gt;
                &lt;option id=&quot;116fc7d5e435153366e0071820d5d6cf&quot; selected_score=&quot;0&quot; unselected_score=&quot;0&quot;&gt;
                  &lt;text&gt;&lt;![CDATA[neg / pos]]&gt;&lt;/text&gt;
                  &lt;explanation&gt;&lt;![CDATA[Option explanation]]&gt;&lt;/explanation&gt;
                &lt;/option&gt;
                &lt;option id=&quot;d58b2b9ed93757a6d450a9e0813513e9&quot; selected_score=&quot;1&quot; unselected_score=&quot;0&quot;&gt;
                  &lt;text&gt;&lt;![CDATA[neg / neg]]&gt;&lt;/text&gt;
                  &lt;explanation&gt;&lt;![CDATA[Option explanation]]&gt;&lt;/explanation&gt;
                &lt;/option&gt;
              &lt;/option_group&gt;
            &lt;/option_groups&gt;
          &lt;/data&gt;
        &lt;/question&gt;
        &lt;question id=&quot;fddb7a47a4fd93f261fa0a690b37716f&quot; type=&quot;GS_Choice_Answer_Question&quot;&gt;
          &lt;metadata&gt;
            &lt;parameters&gt;
              &lt;rescale_score&gt;1&lt;/rescale_score&gt;
              &lt;choice_type&gt;radio&lt;/choice_type&gt;
            &lt;/parameters&gt;
          &lt;/metadata&gt;
          &lt;data&gt;
            &lt;text&gt;&lt;![CDATA[&lt;p&gt;Once again we'll look at sentiment in movie reviews, but this time we'll see if our analysis yields a different result with standard $$Naïve$$ $$Bayes$$  vs. a $$Binarized$$ $$(Boolean$$ $$feature)$$ $$Naïve$$ $$Bayes$$ approach.&lt;/p&gt;

&lt;p&gt;We train our classifier with documents having the following &lt;b&gt;&lt;em&gt;counts&lt;/em&gt;&lt;/b&gt; for key sentiment words, with &lt;em&gt;positive&lt;/em&gt; or &lt;em&gt;negative&lt;/em&gt; class assigned as noted.&lt;/p&gt;

&lt;table&gt;
&lt;tr&gt;&lt;td&gt; &lt;/td&gt;&lt;td&gt;&lt;em&gt;&quot;good&quot;&lt;/em&gt;&lt;/td&gt;&lt;td&gt;&lt;em&gt;&quot;poor&quot;&lt;/em&gt;&lt;/td&gt;&lt;td&gt;&lt;em&gt;&quot;great&quot;&lt;/em&gt;&lt;/td&gt;&lt;td&gt;(class)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;d1.&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;&lt;em&gt;pos&lt;/em&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;d2.&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;&lt;em&gt;pos&lt;/em&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;d3.&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;&lt;em&gt;neg&lt;/em&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;d4.&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;&lt;em&gt;neg&lt;/em&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;d5.&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;2&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;&lt;em&gt;neg&lt;/em&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Now consider the following new review.&lt;/p&gt;
&lt;pre&gt;A good, good plot and great characters, but poor acting.&lt;/pre&gt;

&lt;p&gt;Your task is to assign &lt;em&gt;positive&lt;/em&gt; or &lt;em&gt;negative&lt;/em&gt; sentiment first using standard $$Naïve$$ $$Bayes$$  then with a  $$Binarized$$ $$Naïve$$ $$Bayes$$ approach. Do the different approaches yield the same result in this case? Which of the following matches the pattern of your results? &lt;em&gt;(Hint: Use Add-1 smoothing with &lt;b&gt;both&lt;/b&gt; methods.)&lt;/p&gt;

&lt;p&gt;&lt;b&gt;(response: [&lt;em&gt;standard&lt;/em&gt;] / [&lt;em&gt;binarized&lt;/em&gt;] )&lt;/b&gt;&lt;/p&gt;]]&gt;&lt;/text&gt;
            &lt;explanation&gt;&lt;![CDATA[(See lecture slide on &quot;Binarized (Boolean feature)  Multinomial Naïve Bayes&quot;.) Use the same method in each case, except that for the $$Binarized$$ approach, only count each word a maximum of once per document, i.e., transform the table of counts above to 0 or 1 for each cell.]]&gt;&lt;/explanation&gt;
            &lt;option_groups randomize=&quot;true&quot;&gt;
              &lt;option_group select=&quot;all&quot;&gt;
                &lt;option id=&quot;eccb4e2121cc635283a87b918a15fabe&quot; selected_score=&quot;1&quot; unselected_score=&quot;0&quot;&gt;
                  &lt;text&gt;&lt;![CDATA[pos / pos]]&gt;&lt;/text&gt;
                  &lt;explanation&gt;&lt;![CDATA[Option explanation]]&gt;&lt;/explanation&gt;
                &lt;/option&gt;
                &lt;option id=&quot;7c8283027e775a9227735066f0dd0b72&quot; selected_score=&quot;1&quot; unselected_score=&quot;0&quot;&gt;
                  &lt;text&gt;&lt;![CDATA[pos / neg]]&gt;&lt;/text&gt;
                  &lt;explanation&gt;&lt;![CDATA[Option explanation]]&gt;&lt;/explanation&gt;
                &lt;/option&gt;
                &lt;option id=&quot;d64cdca2de02ebb7ca7ce07d43ce2c9f&quot; selected_score=&quot;0&quot; unselected_score=&quot;0&quot;&gt;
                  &lt;text&gt;&lt;![CDATA[neg / pos]]&gt;&lt;/text&gt;
                  &lt;explanation&gt;&lt;![CDATA[Option explanation]]&gt;&lt;/explanation&gt;
                &lt;/option&gt;
                &lt;option id=&quot;b40a9797a334eb5e51fa3aa774780eeb&quot; selected_score=&quot;0&quot; unselected_score=&quot;0&quot;&gt;
                  &lt;text&gt;&lt;![CDATA[neg / neg]]&gt;&lt;/text&gt;
                  &lt;explanation&gt;&lt;![CDATA[Option explanation]]&gt;&lt;/explanation&gt;
                &lt;/option&gt;
              &lt;/option_group&gt;
            &lt;/option_groups&gt;
          &lt;/data&gt;
        &lt;/question&gt;
      &lt;/question_group&gt;
    &lt;/question_groups&gt;
  &lt;/data&gt;
&lt;/quiz&gt;
</textarea>
<p>
<input type="hidden" name="quiz_id" value="53">
<input type="hidden" name="quiz_type" value="quiz">
<input type="hidden" name="__csrf-token" value="MkUd6tb1Ezpxz4iDvrPz">
<input type="submit" class="btn primary" name="submit" value="Save">
<input type="reset" class="btn info" name="reset" value="Reset" onclick="return confirm('All unsaved changes will be lost. Are you sure?')">
<a href="https://class.coursera.org/nlp-staging/admin/quiz/quiz_selector?quiz_type=quiz" onclick="return confirm('All unsaved changes will be lost. Are you sure?')" class="btn danger">Exit Without Saving</a>
</p>
<style>
  .CodeMirror{
    border: 1px solid #eee;
    
  }
  .CodeMirror-scroll{
    height: auto;
    overflow: visible;
  }
</style>
</form>
<script>$(document).ready(function(){
  CodeMirror.fromTextArea(document.getElementById('quiz_xml'),
  {lineNumbers: true, lineWrapping: true})
  })</script>        </div>
    </div>
            <form target="_blank" id="i18n_form" method="post" action="https://class.coursera.org/nlp-staging/admin/i18n/editor">
    	<span class="hide" id="i18n_span">{"0":"Coursera","1":"Preferences","2":"All Courses","3":"Admin","4":"Support","5":"I18N Editor","6":"About","7":"Contact Us","8":"Logout","9":"Natural Language Processing"}</span>
    	<input type="hidden" name="i18n_strings" id="i18n_strings" />
    </form>
        <div class="hidden">
        This page features MathJax technology to render mathematical formulae.
        If you are using a screen reader, please visit <a href="http://www.dessci.com/en/products/mathplayer/">MathPlayer</a> to download the plugin for your browser. Please note that this is an Internet Explorer-only plugin at this time.
    </div>
</body>

</html>
